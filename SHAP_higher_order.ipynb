{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script allow to investigate the SHAP value extracted from a pytorch model.\n",
    "In addition to \"first-order\" shap value, higher-order SHAP values are obtain from feature masking.\n",
    "The difference between first and higher order SHAP values should give some insight into features interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from itertools import combinations\n",
    "import shap\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data using sklearn classification utilities\n",
    "\n",
    "num_features = 10\n",
    "\n",
    "X, y = generate_data_sklearn(num_features=num_features)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"y\"] = y\n",
    "data[[f\"feature {i}\" for i in range(X.shape[1])]] = X\n",
    "\n",
    "for col in data.columns:\n",
    "    if col != \"y\":\n",
    "        plt.hist(data[col], label=col, alpha=0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own data generation function\n",
    "\n",
    "data = generate_data(\n",
    "    num_samples=5000,\n",
    "    num_features=num_features,\n",
    "    interaction_formula=lambda features: to_bool((features[\"x1\"] + features[\"x2\"])**2 + np.sqrt(np.abs(features[\"x3\"])) \n",
    "                                        + features[\"x4\"] + features[\"x5\"] + 0.2*features[\"x6\"]\n",
    "                                        + features[\"x7\"]**2*features[\"x8\"] + 3*features[\"x9\"] + 0.1*features[\"x10\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data.columns:\n",
    "    if x != \"y\":\n",
    "        plt.hist(data[x], alpha=0.4, label=x, density=True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(data[\"y\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10\n",
    "\n",
    "model = SimpleNN(num_features=num_features)\n",
    "pos_weight = data.y.mean()/(1-data.y.mean())\n",
    "\n",
    "X, y = data.drop(columns=\"y\").to_numpy(), data[\"y\"].to_numpy()\n",
    "\n",
    "# train model on all data\n",
    "X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "early_stopping(model, X_train_tensor, y_train_tensor, pos_weight=0.9/0.1)\n",
    "\n",
    "outputs = model(X_train_tensor).round()\n",
    "\n",
    "print(\"label 1 count = \", outputs.sum())\n",
    "print(\"false_positive = \",  ((outputs == 1) & (y_train_tensor == 0)).sum().item())\n",
    "print(\"false_negative = \", ((outputs == 0) & (y_train_tensor == 1)).sum().item())\n",
    "print(\"f1 score = \", f1_score(y_true=y_train_tensor.detach().numpy(), y_pred=outputs.detach().numpy()))\n",
    "print(\"accuracy = \", accuracy_score(y_true=y_train_tensor.detach().numpy(), y_pred=outputs.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values first order\n",
    "X_background = X_train_tensor[torch.randint(X_train_tensor.shape[0], [500])]  # Smaller sample for SHAP background\n",
    "X_shap = X_train_tensor[torch.randint(X_train_tensor.shape[0], [100])]  # Sample 20 instances for SHAP calculation\n",
    "\n",
    "explainer = shap.GradientExplainer(model, X_background)\n",
    "shap_values_all_features = explainer.shap_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second order shap value\n",
    "\n",
    "# Function to mask specific features by setting them to 0 (or another baseline) for interactions\n",
    "def get_masked_shap_values(model, explainer, data, features_to_mask, baseline=0):\n",
    "    masked_data = data.clone()  # Clone to avoid modifying the original data\n",
    "    masked_data[:, features_to_mask] = baseline  # Set specified features to the baseline value (e.g., 0)\n",
    "    shap_values_masked = explainer.shap_values(masked_data)\n",
    "    return shap_values_masked\n",
    "\n",
    "# Define feature combinations for pairwise and triple interactions\n",
    "#feature_pairs = [(0, 1), (1, 2), (0, 2)]  # Example pairs\n",
    "feature_pairs = list(combinations(range(X.shape[1]), 2))\n",
    "\n",
    "# Analyze pairwise interactions\n",
    "pairwise_interactions = {}\n",
    "for pair in feature_pairs:\n",
    "    # Compute SHAP values with the pair masked\n",
    "    shap_values_pair = get_masked_shap_values(model, explainer, X_shap, pair)\n",
    "    # Calculate interaction by comparing masked SHAP values with original SHAP values\n",
    "    interaction_effect = shap_values_all_features - shap_values_pair\n",
    "    pairwise_interactions[pair] = interaction_effect  # Store result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data: pairwise_interactions dictionary where keys are pairs, and values are the interaction effects\n",
    "# Assume that `pairwise_interactions` contains the mean interaction effect for each feature pair (for simplicity)\n",
    "# Compute the mean interaction effect for each pair across all samples in X_shap\n",
    "mean_interaction_effects = {pair: np.abs(interaction).mean() for pair, interaction in pairwise_interactions.items()}\n",
    "\n",
    "# plot only \n",
    "\n",
    "# Prepare data for heatmap\n",
    "num_features = np.array(list(mean_interaction_effects.keys())).flatten().max()+1\n",
    "interaction_matrix = np.zeros((num_features, num_features))\n",
    "\n",
    "# Calculate mean absolute SHAP values for each individual feature as a baseline\n",
    "individual_shap_values = np.abs(shap_values_all_features).mean(axis=0)\n",
    "\n",
    "# Compute relative interaction effect for each pair\n",
    "relative_interaction_effects = {}\n",
    "for (i, j), interaction in pairwise_interactions.items():\n",
    "    # Mean absolute interaction effect for this pair\n",
    "    mean_interaction = np.abs(interaction).mean()\n",
    "    \n",
    "    # Calculate the baseline effect by combining individual feature impacts\n",
    "    baseline_effect = individual_shap_values[i] + individual_shap_values[j]\n",
    "    \n",
    "    # Calculate relative interaction strength as a proportion\n",
    "    relative_interaction_strength = mean_interaction / baseline_effect if baseline_effect != 0 else 0\n",
    "    relative_interaction_effects[(i, j)] = relative_interaction_strength\n",
    "\n",
    "# Create matrix for heatmap\n",
    "relative_interaction_matrix = np.zeros((num_features, num_features))\n",
    "for (i, j), strength in relative_interaction_effects.items():\n",
    "    relative_interaction_matrix[i, j] = strength\n",
    "    relative_interaction_matrix[j, i] = strength  # Symmetric matrix\n",
    "\n",
    "# Plot heatmap of relative interaction strengths\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(relative_interaction_matrix, annot=True, fmt=\".1%\", cmap=\"coolwarm\",\n",
    "            xticklabels=[f'Feature {i}' for i in range(num_features)],\n",
    "            yticklabels=[f'Feature {i}' for i in range(num_features)],\n",
    "            cbar_kws={'label': 'Relative Interaction Strength'})\n",
    "plt.title(\"Relative Pairwise Feature Interaction Strengths\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_1 = 'x3'  # replace with actual feature names\n",
    "feature_2 = 'x7'\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=data.drop(columns=\"y\"), x=feature_1, y=feature_2, hue=data.y, palette=\"viridis\")\n",
    "plt.title(f\"Interaction between {feature_1} and {feature_2} with target\")\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(data[data.y==0][feature_1], alpha=0.5)\n",
    "plt.hist(data[data.y==1][feature_1], alpha=0.5)\n",
    "plt.hist(data[data.y==0][feature_2], alpha=0.5)\n",
    "plt.hist(data[data.y==1][feature_2], alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
